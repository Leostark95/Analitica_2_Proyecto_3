{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Leostark95/Analitica_2_Proyecto_3/main/df.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de caracteristicas y target (X , y)\n",
    "y = df.TEY\n",
    "X = df.drop(['TEY'], axis = 1)\n",
    "\n",
    "# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state =42)\n",
    "\n",
    "#Imprimir Tamaño de dataset\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", X_train.shape)\n",
    "print(\"Tamaño del conjunto de validación:\",  X_test.shape)\n",
    "\n",
    "\n",
    "#Nombre de caracteristicas númericas\n",
    "numeric_columns=list(X.select_dtypes('float64').columns)\n",
    "\n",
    "#Estandarización de variables númericas\n",
    "pipeline=ColumnTransformer([('num',StandardScaler() ,numeric_columns)], remainder='passthrough')\n",
    "\n",
    "X_train_std = pipeline.fit_transform(X_train)\n",
    "X_test_std = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Crea el modelo\n",
    "ranfor = RandomForestRegressor(\n",
    "            n_estimators = 300,\n",
    "            criterion    = 'squared_error',\n",
    "            n_jobs       = -1,\n",
    "            random_state = 123\n",
    "         )\n",
    "#Calibra el modelo\n",
    "ranfor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Función para calcular el MAPE (Mean Absolute Percentage Error)\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Cargar el conjunto de datos Boston Housing\n",
    "y = df.TEY\n",
    "X = df.drop(['TEY'], axis=1)\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear el modelo de Random Forest para regresión\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE): {mape}')\n",
    "print(f'R^2 Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular el MAPE (Mean Absolute Percentage Error)\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Cargar el conjunto de datos Boston Housing\n",
    "y = df.TEY\n",
    "X = df.drop(['TEY'], axis=1)\n",
    "\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear el modelo de Random Forest para regresión\n",
    "regressor = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Definir la rejilla de hiperparámetros a probar\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Configurar la búsqueda de hiperparámetros\n",
    "grid_search = GridSearchCV(estimator=regressor, param_grid=param_grid, \n",
    "                           cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Entrenar el modelo con la búsqueda de hiperparámetros\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_regressor = grid_search.best_estimator_\n",
    "\n",
    "# Hacer predicciones con el mejor modelo\n",
    "y_pred = best_regressor.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE): {mape}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "\n",
    "# Imprimir los mejores hiperparámetros\n",
    "print(\"Mejores hiperparámetros encontrados:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis del Modelo Random Forest y Ajuste de Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Utilizamos el modelo Random Forest por su robustez y versatilidad en tareas de regresión, además este modelo ayuda a reducir el sobreajuste y mejora la capacidad de generalización. Para evaluar y mejorar su rendimiento, nos enfocamos en hiperparámetros clave como el número de árboles (n_estimators), la profundidad máxima de los árboles (max_depth), y el número de características consideradas para dividir un nodo (max_features). Nos dieron unas métricas, MSE: 0.50, MAE: 0.46, MAPE: 0.34 y R^2 Score: 0.99. Aunque el R^2 nos dio un resultado muy alto lo cual nos hace pensar que el modelo está en su máximo desempeño, decidimos optimizar el rendimiento del modelo, utilizando técnicas como GridSearchCV para ajustar los hiperparámetros. Este método prueba múltiples combinaciones de parámetros y selecciona la mejor configuración basada en validación cruzada. En este caso, GridSearchCV nos permitió identificar los mejores hiperparámetros, lo que nos dio como resultado las siguentes métricas:MSE: 0.52, MAE: 0.47, MAPE: 0.35 y R^2 Score: 0.99. Al no tener un mejoramiento significativo podemos concluir que el modelo está alcanzando su límite de precisión dada la información contenida en los datos actuales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
